# Behavioral-cloning

Self-driving cars are a hot topic that has attracted the attention of many industrial and scientific practitioners. The problem itself consist in teaching a car controller to drive by itself, mimicking human drivers. This repository contains the code for such purpose: clone the behavior of human drivers and generalize the driving. The car controller used for this project is a deep convolutional neural network; a model capable of learning from color images. We refer to it as SimpLeNet, and its main task is to correctly predict the steering angle of the car from input images in a purely end-to-end fashion. 

For fitting the model, roughly 100,000 images were taken from multiple runs in a simulator. The simulator has two distinct circuits: a training circuit, and a test circuit. The car can train only using the first one and the fundamental goal is to generalize the driving for the second circuit. The amount of training images was processed (mainly cropped, scaled and rotated) for generating a final batch of 54,893 images from which SimpLeNet trained. The main concern is that these data are extremely unbalanced, favoring very little steering angles (humans tend to drive smoothly without many sudden changes in the steering, thus favoring driving in nearly straight line). The challenging process was to preprocess the data for filtering this extreme bias towards low angles (that is: driving in straight line), generating synthetic cases in which larger angles are favored. The data augmentation was a critical step for generalizing the driving, and without it the car controller was unable to run properly (read safely) in the test circuit. It is important to highlight that SimpLeNet saw only training examples from the first circuit (the training circuit).

Recall that this is the third project in Udacityâ€™s nanodegree program in self-driving car engineering.
